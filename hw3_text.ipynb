{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab only: Run this cell to download/install packages\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !curl http://www.datasciencecourse.org/assignments/hw3_text.tar.gz --output hw3_text.tar.gz\n",
    "    !tar -xzf hw3_text.tar.gz\n",
    "    !mv hw3_text/* ./\n",
    "    !pip install --upgrade --no-deps --force-reinstall git+https://github.com/locuslab/mugrade.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "In this problem, you will be again analyzing the Twitter data we extracted from 2016 using [this](https://dev.twitter.com/overview/api) api. This time, we extracted the tweets posted by the following six Twitter accounts: `realDonaldTrump, mike_pence, GOP, HillaryClinton, timkaine, TheDemocrats`.\n",
    "\n",
    "For every tweet, we collected two pieces of information:\n",
    "- `screen_name`: the Twitter handle of the user tweeting and\n",
    "- `text`: the content of the tweet.\n",
    "\n",
    "We divided the tweets into two parts - the train and test sets.  The training set contains both the `screen_name` and `text` of each tweet; the test set only contains the `text`.\n",
    "\n",
    "The overarching goal of the problem is to infer the political inclination (whether **R**epublican or **D**emocratic) of the author from the tweet text. The ground truth (i.e., true class labels) are determined from the `screen_name` of the tweet as follows:\n",
    "- **R**: `realDonaldTrump, mike_pence, GOP`\n",
    "- **D**: `HillaryClinton, timkaine, TheDemocrats`\n",
    "\n",
    "We can treat this as a binary classification problem. We'll follow this common structure to tackling this problem:\n",
    "\n",
    "1. **preprocessing**: clean up the raw tweet text using regular expressions, and produce class labels\n",
    "2. **features**: construct bag-of-words feature vectors\n",
    "3. **classification**: learn a binary classification model using [`scikit-learn`](http://scikit-learn.org/stable/modules/classes.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "from scipy.sparse import csr_matrix\n",
    "import string\n",
    "import numpy as np\n",
    "import sklearn\n",
    "# from sklearn import cross_validation\n",
    "# import sklearn.feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.metrics\n",
    "import gzip\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mugrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A. Text Processing\n",
    "\n",
    "### Q1 Preprocessing\n",
    "Your first task is to fill in the following function which processes and tokenizes raw text. You will need to preprocess the tokens by applying the operators _in the following order_.\n",
    "\n",
    "1. Convert the text to lower case.\n",
    "2. Remove any URLs, which in this case will all be of the form `http://t.co/<alphanumeric characters>`.\n",
    "3. Remove all trailing `'s` characters, followed by other apostrophes:\n",
    "   - remove trailing `'s`: `Children's` becomes `children`\n",
    "   - omit other apostrophes: `don't` becomes `dont`\n",
    "4. Remove all non-alphanumeric (i.e., A-Z, a-z, 0-9) characters (replacing them with a single space)\n",
    "5. Split the remaining text by whitespace into an array of individual words\n",
    "6. Discard empty strings (i.e., if the string after processing above is equal to \"\"), return an empty array `[]` rather than `['']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local tests for function preprocess():\n",
      "  Test 1 PASSED\n",
      "  Test 2 PASSED\n",
      "  Test 3 PASSED\n",
      "  Test 4 PASSED\n",
      "  Test 5 PASSED\n",
      "  Test 6 PASSED\n",
      "  Test 7 PASSED\n",
      "  Test 8 PASSED\n",
      "  Test 9 PASSED\n",
      "  Test 10 PASSED\n",
      "  Test 11 PASSED\n",
      "  Test 12 PASSED\n",
      "  Test 13 PASSED\n",
      "  Test 14 PASSED\n",
      "  Test 15 PASSED\n"
     ]
    }
   ],
   "source": [
    "@mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\" Normalizes case and handles punctuation\n",
    "    \n",
    "    args:\n",
    "        text: str -- raw text\n",
    "\n",
    "    Outputs:\n",
    "        list(str): tokenized text\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\w*://t.co/\\w+','',text)\n",
    "#     text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text, flags=re.MULTILINE)\n",
    "#     text = re.sub(r'http.*', '', text)\n",
    "    text= text.replace(\"'s\", '')\n",
    "    text = text.replace(\"'\", '')\n",
    "    text = text.replace('\"', '')\n",
    "    pattern = \"[^0-9a-zA-Z\\s]+\"\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Loading Data\n",
    "\n",
    "Using this preprocess function, load the data from the relevant csv files and return a list of the parsed tweets, plus a flag indicating whether or not the tweet is from a republican (i.e., one of the three usernames mentioned above); for the test data, where no screen name is given, provide `None` as the flag).  Note that this function should take less than a second if you've implemented the above preprocessing function efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    \"\"\"Reads the dataset from the tweets_train.csv.gz and tweets_test.csv.gz files\n",
    "    \n",
    "    return : Tuple (data_train, data_test)\n",
    "        data_train : List[Tuple[is_republican, tokenized_tweet]]\n",
    "            is_republican : bool -- True if tweet is from a republican\n",
    "            tokenized_tweet : List[str] -- the tweet, tokenized by preprocess()\n",
    "        data_test : List[Tuple[None, tokenized_tweet]\n",
    "            None: the Python constant \"None\"\n",
    "            tokenized_tweet : List[str] -- the tweet, tokenized by preprocess()\n",
    "    \"\"\"\n",
    "    test_file = '/Users/cindyhuang/Downloads/hw3_text 2/tweets_test.csv.gz'\n",
    "    train_file = '/Users/cindyhuang/Downloads/hw3_text 2/tweets_train.csv.gz'\n",
    "    df_test = pd.read_csv(test_file,compression='gzip')\n",
    "    df_test = df_test['text'] \n",
    "    df_train = pd.read_csv(train_file,compression='gzip')\n",
    "    df_train_text= df_train['text']\n",
    "    df_account_name = df_train['screen_name']\n",
    "\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "\n",
    "    republican = ['realDonaldTrump', 'mike_pence', 'GOP']\n",
    "\n",
    "    for tweet in df_test:\n",
    "        processed_test = preprocess(tweet)\n",
    "        data_test.append((None, processed_test))\n",
    "\n",
    "    for account, tweet in (zip(df_account_name.values, df_train_text.values)):\n",
    "        processed_train = preprocess(tweet)\n",
    "        is_republican = bool(account in republican)\n",
    "        data_train.append((is_republican,processed_train))\n",
    "\n",
    "\n",
    "    return (data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Feature Construction\n",
    "\n",
    "The next step is to derive feature vectors from the tokenized tweets. In this section, you will be constructing a bag-of-words [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) feature vector.\n",
    "\n",
    "\n",
    "### Q3 Word distributions\n",
    "The number of possible words is prohibitively large, and not all words are useful for our task. We will begin by filtering the vectors using a common heuristic: We calculate a frequency distribution of words in the corpus and remove words at the head (most frequent) and tail (least frequent) of the distribution. Most frequently used words (often called stopwords) provide very little information about the similarity of two pieces of text. Words with extremely low frequency tend to be typos.\n",
    "\n",
    "We will now implement a function that counts the number of times that each token is used in the training corpus. You should return a [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) object with the number of times that each word appears in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local tests for function get_distribution():\n",
      "17991\n",
      "3941\n",
      "  Test 1 PASSED\n",
      "  Test 2 PASSED\n",
      "  Test 3 PASSED\n",
      "  Test 4 PASSED\n",
      "  Test 5 PASSED\n"
     ]
    }
   ],
   "source": [
    "@mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "def get_distribution(data):\n",
    "    \"\"\" Calculates the word count distribution.\n",
    "\n",
    "    args: \n",
    "        data -- the training or testing data\n",
    "\n",
    "    return : collections.Counter -- the distribution of word counts\n",
    "    \"\"\"\n",
    "    word_frequency = Counter()\n",
    "    for text in data:\n",
    "        vocab = text[1]\n",
    "        for word in vocab:\n",
    "            word_frequency[word] += 1\n",
    "#     print(len(word_frequency))\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17990\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = read_data()\n",
    "dist_train = get_distribution(data_train)\n",
    "dist_test = get_distribution(data_test)\n",
    "# print(len(dist_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function, once implemented properly, to get a sense of the distribution of words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train, data_test = read_data()\n",
    "dist_train = get_distribution(data_train)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.hist(dist_train.values(), bins=np.logspace(0,4,100));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the plot looks roughly linear on this log-log plot (for those we are curious, this is a phenomenon known as [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law)).  For us, however, it largely means that there are many words that appear many times (i.e., common words like \"the\"), which thus won't be very predictive for our task, because they are unlike to differentiate Republican vs. Democratic tweets.  There are also words that appear very infrequently, which also means that they aren't going to be very predictive, but for a different reason: these words likely won't occur very often in the test set, and thus will largely just cause the classifier to overfit to the training set.  However, instead of removing these words manually, in the next question, we will use the TFIDF weighting and vectorizer to both remove overly-common words and exclude too-infrequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 Vectorizing\n",
    "\n",
    "Now we have each tweet as a list of words, excluding words with high and low frequencies. We want to convert these into a sparse feature matrix, where each row corresponds to a tweet and each column to a possible word. We can use `scikit-learn`'s [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to do this quite easily.\n",
    "\n",
    "Instructions:\n",
    " - By default, the `TfidfVectorizer` does its own tokenization, but we've already done it above, so you need to pass `preprocessor = lambda x : x, tokenization = lambda x : x, token_pattern=None` as arguments to the class constructor.\n",
    " - The vectorizer can filter words that are too uncommon or too common: to do this, set the `min_df=5` argument (words must be contained in more than 5 tweets), and `max_df=0.4` argument (filter out words contained in more than 40% of tweets)\n",
    " - You should use only the training data to `fit` or `fit_transform` the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local tests for function create_features():\n",
      "  Test 1 PASSED\n",
      "  Test 2 PASSED\n",
      "  Test 3 PASSED\n",
      "  Test 4 PASSED\n",
      "  Test 5 PASSED\n",
      "  Test 6 PASSED\n"
     ]
    }
   ],
   "source": [
    "@mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "def create_features(train_data, test_data):\n",
    "    \"\"\"creates the feature matrices and label vector for the training and test sets.\n",
    "\n",
    "    args:\n",
    "        train_data, test_data : output of read_data() function\n",
    "\n",
    "    returns: Tuple[train_features, train_labels, test_features]\n",
    "        train_features : scipy.sparse.csr.csr_matrix -- TFIDF feature matrix for the training set\n",
    "        train_labels : np.array[num_train] -- a numpy vector, where 1 stands for Republican and 0 stands for Democrat \n",
    "        test_features : scipy.sparse.csr.csr_matrix -- TFIDF feature matrix for the test set\n",
    "    \"\"\"\n",
    "    test_text = [i for boolean, i in test_data]\n",
    "    train_text = [i for boolean, i in train_data]\n",
    "    \n",
    "    num_train = []\n",
    "    for boolean, text in train_data:\n",
    "        if boolean:\n",
    "            num_train.append(1)\n",
    "        else:\n",
    "            num_train.append(0)\n",
    "            \n",
    "    train_labels = np.array(num_train)\n",
    "    \n",
    "    tfidfvectorizer = TfidfVectorizer(preprocessor = lambda x : x, tokenizer = lambda x : x, token_pattern=None,\n",
    "                                    min_df=5, max_df=0.40)\n",
    "    \n",
    "    train_features = tfidfvectorizer.fit_transform(train_text)\n",
    "    \n",
    "    test_features = tfidfvectorizer.transform(test_text)\n",
    "    \n",
    "    return ([train_features, train_labels, test_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 551)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = read_data()\n",
    "train_features, train_labels, test_features = create_features(data_train, data_test)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the created matrices are very sparse, which is to be expected especially for tweets (given that each tweet can only contain relatively few words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Classification\n",
    "\n",
    "We are now ready to put it all together and train the classification model.\n",
    "\n",
    "You will be using the Support Vector Machine [`sklearn.svm.LinearSVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn). This class implements a linear SVM as we described in class, though of course, the details vary a little bit with this particular implementation.\n",
    "\n",
    "### Q5 Training a classifier\n",
    "\n",
    "Let's begin by training a classifier. You should specifically train a `LinearSVC` with a given set of features and labels, plus the regularization parameter specified by `C`.  You can additionally include as arguments to the `LinearSVC` class the `loss = \"hinge\"` argument (so that this is a typical SVM), and the `random_state=0` argument (to avoid any randomness in the training).  **Additionally, you should use the `max_iter=10000` argument to make sure that you run for enough iterations to avoid any failure to converge given the regularization parameters we use**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local tests for function train_classifier():\n",
      "  Test 1 PASSED\n",
      "  Test 2 PASSED\n",
      "  Test 3 PASSED\n",
      "  Test 4 PASSED\n",
      "  Test 5 PASSED\n",
      "  Test 6 PASSED\n",
      "  Test 7 PASSED\n",
      "  Test 8 PASSED\n",
      "  Test 9 PASSED\n"
     ]
    }
   ],
   "source": [
    "@mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "def train_classifier(features, labels, C):\n",
    "    \"\"\"learns a classifier from the input features and labels using a specified kernel function\n",
    "\n",
    "    args:\n",
    "        features: scipy.sparse.csr.csr_matrix -- sparse matrix of features\n",
    "        labels : numpy.ndarray(bool): binary vector of class labels\n",
    "        C : float -- C regularization parameters\n",
    "\n",
    "    returns: sklearn.svm.LinearSVC -- classifier trained on data\n",
    "    \"\"\"\n",
    "    lsvc = LinearSVC(loss = \"hinge\",random_state=0, max_iter=10000, C = C)\n",
    "#     print(features.shape)\n",
    "    classifier = lsvc.fit(features, labels)\n",
    "\n",
    "    \n",
    "    return  classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Cross validation\n",
    "\n",
    "After building the function to train this classifier, let's now use a validation set to pick the optimal value of `C`, out of the choices of `(0.01, 0.1, 1.0, 10.0)`.  The basic approach here will be to split the training set into the first 10000 samples for the training set, and the remainder for the validation set, allowing you to choose the best parameter to use on the training set.  To evaluate the quality of the classifier, you will use the [F1 score](https://en.wikipedia.org/wiki/F-score), a common metric for text classification, which you can compute using the `sklearn.metrics.f1_score` function.\n",
    "\n",
    "Specifically, you should implement the function below, which will compute the training and validation F1 score for different classifiers trained with different values of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local tests for function evaluate_classifier():\n",
      "1.0\n",
      "  Test 1 FAILED         assert objects_equal(evaluate_classifier(X_train, y_train, train_length=10000), [(0.8159452460229375, 0.8038593373111591), (0.8819796954314721, 0.8541207580431908), (0.9490116573745565, 0.8917251051893409), (0.9841810172206648, 0.8730377306527127), (0.9957991598319663, 0.8518874399450926)])\n",
      "0.5\n",
      "  Test 2 FAILED         assert objects_equal(evaluate_classifier(X_train, y_train, C=(0.5, 5.0), train_length=10000), [(0.9351312697926243, 0.8861834654586637), (0.975057597916458, 0.8800221668052092)])\n"
     ]
    }
   ],
   "source": [
    "# @mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "def evaluate_classifier(features, labels, C = (0.01, 0.1, 1.0, 10., 100.), train_length=10000):\n",
    "    \"\"\" Train multiple classifier based on the first train_length features of features/labels,\n",
    "        one for each regularization parameter supplied in C, and return train/validation f1\n",
    "        scores for each of the classifiers\n",
    "    \n",
    "    args:\n",
    "        features: scipy.sparse.csr.csr_matrix -- sparse matrix of features\n",
    "        labels : numpy.ndarray(bool): binary vector of class labels\n",
    "        C : Tuple[float] -- tuple of C regularization parameters\n",
    "        train_length: int -- use _first_ train_length features for training (and the rest of validation)\n",
    "    \n",
    "    return : List[Tuple[float, float]] -- list of F1 scores for training/validation for each C parameter\n",
    "    \"\"\"\n",
    "    train_idx=[i for i in range(train_length)]\n",
    "    val_idx = [i for i in range(train_length, features.shape[0])]\n",
    "    \n",
    "    train_features = features[train_idx, :].todense()\n",
    "    val_features = features[val_idx,:].todense()\n",
    "    train_features = csr_matrix(train_features)\n",
    "    val_features = csr_matrix(val_features)\n",
    "    train_label = labels[:train_length]\n",
    "    val_label = labels[train_length:]\n",
    "    \n",
    "    \n",
    "    val_test = []\n",
    "    c_d = dict()\n",
    "    \n",
    "    classifier_result = []\n",
    "    for i in C:\n",
    "        train = train_classifier(train_features, train_label, i)\n",
    "        train_score = f1_score(train_label,train.predict(train_features))\n",
    "        test_score = f1_score(val_label,train.predict(val_features))\n",
    "        val_test.append(test_score)\n",
    "        classifier_result.append((train_score, test_score))\n",
    "        c_d[test_score] = i\n",
    "    \n",
    "    print(c_d[max(val_test)])\n",
    "        \n",
    "        \n",
    "    return classifier_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cindy output: [(0.8159452460229375, 0.8038593373111591), (0.8819796954314721, 0.8541207580431908), (0.9489154672613013, 0.8917251051893409), (0.9841810172206648, 0.8730377306527127), (0.9957991598319663, 0.8518874399450926)]\n",
      "local test case:  [(0.8159452460229375, 0.8038593373111591), (0.8819796954314721, 0.8541207580431908), (0.9490116573745565, 0.8917251051893409), (0.9841810172206648, 0.8730377306527127), (0.9957991598319663, 0.8518874399450926)]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = read_data()\n",
    "X_train, y_train, _ = create_features(data_train, data_test)\n",
    "\n",
    "print('Cindy output:',evaluate_classifier(X_train, y_train, train_length=10000))\n",
    "print('local test case: ', [(0.8159452460229375, 0.8038593373111591), (0.8819796954314721, 0.8541207580431908), (0.9490116573745565, 0.8917251051893409), (0.9841810172206648, 0.8730377306527127), (0.9957991598319663, 0.8518874399450926)])\n",
    "\n",
    "# print('local test case: ', [(0.9351312697926243, 0.8861834654586637), (0.975057597916458, 0.8800221668052092)])\n",
    "# [(0.8159452460229375, 0.8038593373111591), (0.8819796954314721, \n",
    "# 0.8541207580431908), (0.9490116573745565, 0.8917251051893409),\n",
    "#  (0.9841810172206648, 0.8730377306527127)]\n",
    "\n",
    "\n",
    "# [(0.8159452460229375, 0.8038593373111591), (0.8819796954314721, 0.8541207580431908), (0.9490116573745565, 0.8917251051893409), (0.9841810172206648, 0.8730377306527127), (0.9957991598319663, 0.8518874399450926)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 Classifying new Tweets\n",
    "\n",
    "Finally, let's put this all together.  Using the _best_ `C` value you found in the previous part (i.e., build the classifiers and test which `C` value out of `(0.01, 0.1, 1.0, 10., 100.)` gives the highest F1 score on the _validation_ set (you can hardcode this value into the function below), train a classifier on the _entire_ training set, and make predictions for the test set.  You won't be able to evaluate how accurate these predictions are, of course, but you can use this classifier to classify tweets as being from Republican or Democratic sources (or perhaps more precisely, from being from one of the three aforementioned Republicans or three Democrats during the 2016 election)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local tests for function predict_test():\n",
      "  Test 1 PASSED\n",
      "  Test 2 PASSED\n"
     ]
    }
   ],
   "source": [
    "# @mugrade.local_tests\n",
    "# @mugrade.submit_tests('28PY3HJpnZGQT8R2VgdC')\n",
    "\n",
    "def predict_test(train_features, train_labels, test_features):\n",
    "    \"\"\"train the classifier on the training set and return predictions on the test set\n",
    "    \n",
    "    args:\n",
    "        train_features: scipy.sparse.csr.csr_matrix -- sparse matrix of training features\n",
    "        train_labels : numpy.ndarray(bool): binary vector of training class labels\n",
    "        test_features: scipy.sparse.csr.csr_matrix -- sparse matrix of test set features\n",
    "\n",
    "    return : numpy.ndarray(bool): array of predictions on the test set\n",
    "    \"\"\"\n",
    "    C = 1.0\n",
    "    train = train_classifier(train_features, train_labels, C)\n",
    "    return train.predict(test_features)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
